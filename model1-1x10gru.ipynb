{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EB5002 Text Processing\n",
    "\n",
    "# Base Models\n",
    "\n",
    "Code adapted from <https://www.kaggle.com/alvations/gru-language-model>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tkokkeng/Documents/EB5002-TextProcessing'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.path.sep, 'home', 'tkokkeng', 'Documents', 'EB5002-TextProcessing'))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/tkokkeng/python/python367/ptvenv/lib/python36.zip',\n",
       " '/home/tkokkeng/python/python367/ptvenv/lib/python3.6',\n",
       " '/home/tkokkeng/python/python367/ptvenv/lib/python3.6/lib-dynload',\n",
       " '/usr/lib/python3.6',\n",
       " '',\n",
       " '/home/tkokkeng/python/python367/ptvenv/lib/python3.6/site-packages',\n",
       " '/home/tkokkeng/.local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/home/tkokkeng/.local/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/tkokkeng/.ipython',\n",
       " '/home/tkokkeng/Documents/EB5002-TextProcessing/source']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "if os.path.join(os.getcwd(), 'source') not in sys.path:\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'source'))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "feb13fc88688cd77d0f4266f0d95f6b5e341bfa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fefccf4a6d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b6e71245b5e82a99ce01f914e6efc37e5dd771b0"
   },
   "outputs": [],
   "source": [
    "try: # Use the default NLTK tokenizer.\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    # Sometimes it doesn't work on some machines because of setup issues.\n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except: # Use a naive sentence tokenizer and toktok.\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    # See https://stackoverflow.com/a/25736515/610569\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    # Use the toktok tokenizer that requires no dependencies.\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e66bf66fae3734f95241eebc5ac8d11e61718bfe"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "import io #codecs\n",
    "\n",
    "# Text version of https://kilgarriff.co.uk/Publications/2005-K-lineer.pdf\n",
    "# if os.path.isfile('language-never-random.txt'):\n",
    "#     with io.open('language-never-random.txt', encoding='utf8') as fin:\n",
    "#         text = fin.read()\n",
    "# else:\n",
    "#     url = \"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\"\n",
    "#     text = requests.get(url).content.decode('utf8')\n",
    "#     with io.open('language-never-random.txt', 'w', encoding='utf8') as fout:\n",
    "#         fout.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "10e3d0a9d7d39774d41e60326ecf82f939dedcf6"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text.\n",
    "# tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "#                   for sent in sent_tokenize(text)]\n",
    "\n",
    "with io.open(os.path.join('data', 'tokenised-tweets.txt'), encoding='utf8') as infile:\n",
    "    tokenized_text = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d971921fc3975505d0db84eca326744fb98c1ced"
   },
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        \n",
    "        # Initialize the vocab \n",
    "        special_tokens = {'<pad>': 0, '<unk>':1, '<s>':2, '</s>':3}\n",
    "        self.vocab = Dictionary(texts)\n",
    "        self.vocab.patch_with_special_tokens(special_tokens)\n",
    "        \n",
    "        # Keep track of the vocab size.\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "        # Keep track of how many data points.\n",
    "        self._len = len(texts)\n",
    "        \n",
    "        # Find the longest text in the data.\n",
    "        self.max_len = max(len(txt) for txt in texts) \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_sent = self.vectorize(self.texts[index])\n",
    "        x_len = len(vectorized_sent)\n",
    "        # To pad the sentence:\n",
    "        # Pad left = 0; Pad right = max_len - len of sent.\n",
    "        pad_dim = (0, self.max_len - len(vectorized_sent))\n",
    "        vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "        return {'x':vectorized_sent[:-1], \n",
    "                'y':vectorized_sent[1:], \n",
    "                'x_len':x_len}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens, start_idx=2, end_idx=3):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        \n",
    "        vectorized_sent = [start_idx] + self.vocab.doc2idx(tokens) + [end_idx]\n",
    "        return torch.tensor(vectorized_sent)\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4e39ea3edc9855cbc71e0b4e8c18dd1ca84e827f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11368"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data = TweetsDataset(tokenized_text)\n",
    "len(tweets_data.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "149f189249edf73258f9456e86c2116cc2da3150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[    2,    33,   296,  ...,     3,     0,     0],\n",
      "        [    2,  1640,    25,  ...,     0,     0,     0],\n",
      "        [    2,    23,  1370,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,   144,  5033,  ...,     0,     0,     0],\n",
      "        [    2,    35, 11365,  ...,     0,     0,     0],\n",
      "        [    2,   479,    88,  ...,     0,     0,     0]]), 'y': tensor([[   33,   296,   566,  ...,     0,     0,     0],\n",
      "        [ 1640,    25,    14,  ...,     0,     0,     0],\n",
      "        [   23,  1370,  1244,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  144,  5033,     3,  ...,     0,     0,     0],\n",
      "        [   35, 11365,     3,  ...,     0,     0,     0],\n",
      "        [  479,    88,     3,  ...,     0,     0,     0]]), 'x_len': tensor([36, 34, 32, 31, 30, 30, 29, 29, 29, 29, 28, 28, 27, 27, 27, 26, 26, 26,\n",
      "        25, 25, 25, 25, 25, 25, 24, 24, 23, 23, 22, 22, 22, 22, 22, 21, 21, 20,\n",
      "        20, 20, 20, 20, 20, 19, 19, 18, 18, 18, 18, 17, 17, 17, 17, 17, 16, 16,\n",
      "        16, 16, 16, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11,\n",
      "        11, 11, 10, 10, 10, 10, 10,  9,  9,  9,  9,  8,  8,  7,  7,  7,  7,  7,\n",
      "         7,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5,  5,  5,  5,  5,  5,  4,  4,\n",
      "         4,  4])}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "dataloader = DataLoader(dataset=tweets_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "5aa5c2bd3bd13d6870441dec284d7762d6b8f1bd"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        \n",
    "        # Initialize the GRU with the \n",
    "        # - size of the input (i.e. embedding layer)\n",
    "        # - size of the hidden layer \n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Initialize the \"classifier\" layer to map the RNN outputs\n",
    "        # to the vocabulary. Remember we need to -1 because the \n",
    "        # vectorized sentence we left out one token for both x and y:\n",
    "        # - size of hidden_size of the GRU output.\n",
    "        # - size of vocabulary\n",
    "        self.classifier = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs, use_softmax=False, hidden=None):\n",
    "        # Look up for the embeddings for the input word indices.\n",
    "        embedded = self.embedding(inputs)\n",
    "        # Put the embedded inputs into the GRU.\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        # Matrix manipulation magic.\n",
    "        batch_size, sequence_len, hidden_size = output.shape\n",
    "        # Technically, linear layer takes a 2-D matrix as input, so more manipulation...\n",
    "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)\n",
    "        # Apply dropout.\n",
    "        output = F.dropout(output, 0.5)\n",
    "        # Put it through the classifier\n",
    "        # And reshape it to [batch_size x sequence_len x vocab_size]\n",
    "        output = self.classifier(output).view(batch_size, sequence_len, -1)\n",
    "        \n",
    "        return (F.softmax(output,dim=2), hidden) if use_softmax else (output, hidden)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "dce2418b4cede1f5dd3f104179fa69defaeceac3"
   },
   "outputs": [],
   "source": [
    "# Set the hidden_size of the GRU \n",
    "embed_size = 12\n",
    "hidden_size = 10\n",
    "num_layers = 1\n",
    "\n",
    "_encoder = Generator(len(tweets_data.vocab), embed_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "0d24dcec5ce293c82663ecf9ce07528d1f125882"
   },
   "outputs": [],
   "source": [
    "# Take a batch.\n",
    "batch_size = 128\n",
    "dataloader = DataLoader(dataset=tweets_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "_batch = next(iter(dataloader))\n",
    "_inputs, _lengths = _batch['x'], _batch['x_len']\n",
    "_targets = _batch['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,   70,  121,   59,  237,   68,   59,    9,   66,  362,  272,  130,\n",
       "         794, 2779,   59, 2777,   48, 1721,   59, 2775,   48,  372, 2778,   20,\n",
       "         745,  851,  266, 2780, 2776,   39,    3,    0,    0,    0,    0,    0,\n",
       "           0,    0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  70,  121,   59,  237,   68,   59,    9,   66,  362,  272,  130,  794,\n",
       "        2779,   59, 2777,   48, 1721,   59, 2775,   48,  372, 2778,   20,  745,\n",
       "         851,  266, 2780, 2776,   39,    3,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "009c1cc8d9f7517187bd9259473703baf5cbd349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sizes:\t torch.Size([128, 38, 11368])\n",
      "Input sizes:\t 128 38 11368\n",
      "Target sizes:\t torch.Size([128, 38])\n"
     ]
    }
   ],
   "source": [
    "_output, _hidden = _encoder(_inputs)\n",
    "print('Output sizes:\\t', _output.shape)\n",
    "print('Input sizes:\\t', batch_size, tweets_data.max_len -1, len(tweets_data.vocab))\n",
    "print('Target sizes:\\t', _targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "b5ddd1dfa0736a64152d1b3acbedb118606d4a38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 38, 11368])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "ee773d9ff037f57b0ba49a0594f5ffb546da3498"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38, 11368])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "07a81647f4724bc89e31eb0aaca301839d23b9fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 38])\n"
     ]
    }
   ],
   "source": [
    "_, predicted_indices = torch.max(_output, dim=2)\n",
    "print(predicted_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "cc11b8af72aa329ceb43d3b9e40d96efea23cb84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyperparams(embed_size=256, hidden_size=256, num_layers=1, loss_func=<class 'torch.nn.modules.loss.CrossEntropyLoss'>, learning_rate=0.03, optimizer=<class 'torch.optim.adam.Adam'>, batch_size=128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "_hyper = ['embed_size', 'hidden_size', 'num_layers',\n",
    "          'loss_func', 'learning_rate', 'optimizer', 'batch_size']\n",
    "Hyperparams = namedtuple('Hyperparams', _hyper)\n",
    "\n",
    "\n",
    "hyperparams = Hyperparams(embed_size=256, hidden_size=256, num_layers=1,\n",
    "                          loss_func=nn.CrossEntropyLoss,\n",
    "                          learning_rate=0.03, optimizer=optim.Adam, batch_size=128)\n",
    "\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "2654e746605c6480d1cc4cc1cf8b6c59fa3eefa4"
   },
   "outputs": [],
   "source": [
    "# Training routine.\n",
    "def train(num_epochs, dataloader, model, criterion, optimizer):\n",
    "    losses = []\n",
    "    plt.ion()\n",
    "    for _e in range(num_epochs):\n",
    "        for batch in tqdm(dataloader):\n",
    "            # Zero gradient.\n",
    "            optimizer.zero_grad()\n",
    "            x = batch['x'].to(device)\n",
    "            # x_len = batch['x_len'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            # Feed forward. \n",
    "            output, hidden = model(x, use_softmax=False)\n",
    "            # Compute loss:\n",
    "            # Shape of the `output` is [batch_size x sequence_len x vocab_size]\n",
    "            # Shape of `y` is [batch_size x sequence_len]\n",
    "            # CrossEntropyLoss expects `output` to be [batch_size x vocab_size x sequence_len]\n",
    "            _, prediction = torch.max(output, dim=2)\n",
    "            loss = criterion(output.permute(0, 2, 1), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.float().data)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(losses)\n",
    "        plt.pause(0.05)\n",
    "\n",
    "\n",
    "def initialize_data_model_optim_loss(hyperparams):\n",
    "    # Initialize the dataset and dataloader.\n",
    "    tweets_data = TweetsDataset(tokenized_text)\n",
    "    dataloader = DataLoader(dataset=tweets_data, \n",
    "                            batch_size=hyperparams.batch_size, \n",
    "                            shuffle=True)\n",
    "\n",
    "    # Loss function.\n",
    "    criterion = hyperparams.loss_func(ignore_index=tweets_data.vocab.token2id['<pad>'], \n",
    "                                      reduction='mean')\n",
    "\n",
    "    # Model.\n",
    "    model = Generator(len(tweets_data.vocab), hyperparams.embed_size, \n",
    "                      hyperparams.hidden_size, hyperparams.num_layers).to(device)\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = hyperparams.optimizer(model.parameters(), lr=hyperparams.learning_rate)\n",
    "    \n",
    "    return dataloader, model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "5a5b3b2c17ba23fbb976f4a634ddd21e80e26c91"
   },
   "outputs": [],
   "source": [
    "def generate_example(model, temperature=1.0, max_len=100, hidden_state=None):\n",
    "    start_token, start_idx = '<s>', 2\n",
    "    # Start state.\n",
    "    inputs = torch.tensor(tweets_data.vocab.token2id[start_token]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    sentence = [start_token]\n",
    "    i = 0\n",
    "    while i < max_len and sentence[-1] not in ['</s>', '<pad>']:\n",
    "        i += 1\n",
    "        \n",
    "        embedded = model.embedding(inputs)\n",
    "        output, hidden_state = model.gru(embedded, hidden_state)\n",
    "\n",
    "        batch_size, sequence_len, hidden_size = output.shape\n",
    "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)    \n",
    "        output = model.classifier(output).view(batch_size, sequence_len, -1).squeeze(0)\n",
    "        #_, prediction = torch.max(F.softmax(output, dim=2), dim=2)\n",
    "        \n",
    "        word_weights = output.div(temperature).exp().cpu()\n",
    "        if len(word_weights.shape) > 1:\n",
    "            word_weights = word_weights[-1] # Pick the last word.    \n",
    "        word_idx = torch.multinomial(word_weights, 1).view(-1)\n",
    "        \n",
    "        sentence.append(tweets_data.vocab[int(word_idx)])\n",
    "        \n",
    "        inputs = tensor([tweets_data.vocab.token2id[word] for word in sentence]).unsqueeze(0).to(device)\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "de7efc9371e23d8ec2c73d647fdfc06a2805a573"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparams = Hyperparams(embed_size=256, hidden_size=256, num_layers=1,\n",
    "                          loss_func=nn.CrossEntropyLoss,\n",
    "                          learning_rate=0.03, optimizer=optim.Adam, batch_size=128)\n",
    "\n",
    "dataloader, model, optimizer, criterion = initialize_data_model_optim_loss(hyperparams)\n",
    "\n",
    "train(100, dataloader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "67548caaf4b02520b3eefcc87e5b7550ceff3e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> know get real ' s families was with the support the nra and . </s>\n",
      "<s> i ' ve witnessed they don ' t so : end that would the many leader of them in her the things stop what my ” — @potus </s>\n",
      "<s> the business interests. </s>\n",
      "<s> please the \" - a more college campaign , \" : i think </s>\n",
      "<s> join me , but you my was right , , but his , we will never be doing , look ! #makeamericagreatagain </s>\n",
      "<s> many see what the inclusive the american campaign from it ' s time for is done for the american woman in donald trump in decisions to . </s>\n",
      "<s> thank hillary with ! </s>\n",
      "<s> it will today them . </s>\n",
      "<s> you come , , join us- us , and or in the iowa , tomorrow , he didn and , ! </s>\n",
      "<s> ted florida of trump in too the new ! </s>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    generate_example(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "8f2b7153dbe720c1fccbcbf5f8512a2bcce47689"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "torch.save(model.state_dict(), os.path.join('models', 'gru-model1.pth'))\n",
    "\n",
    "hyperparams = Hyperparams(embed_size=256, hidden_size=256, num_layers=1,\n",
    "                          loss_func='nn.CrossEntropyLoss',\n",
    "                          learning_rate=0.03, optimizer='optim.Adam', batch_size=128)\n",
    "\n",
    "with open(os.path.join('models', 'gru-model1.json'), 'w') as fout:\n",
    "    json.dump(dict(hyperparams._asdict()), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "fab8a4a413865aec5d69910460576fcf450896e2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptvenv",
   "language": "python",
   "name": "ptvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
